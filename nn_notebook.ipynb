{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66ffb618",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ddd8328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.restoration import denoise_wavelet\n",
    "from sklearn import model_selection\n",
    "from nexcsi import decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28fcb30",
   "metadata": {},
   "source": [
    "# Initial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0bdb484",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"raspberrypi\"\n",
    "raw_data_path = \"./Data8_Train/room/Red\"\n",
    "processed_path = \"./train_data\"\n",
    "classes = [\"empty\", \"walk\", \"jump\", \"wave\"]\n",
    "activity_code = {\n",
    "    \"EMPTY\": \"1\",\n",
    "    \"WALK\": \"4\",\n",
    "    \"STAND\": \"3\",\n",
    "    \"SIT\": \"5\",\n",
    "}\n",
    "activity_vector = {\n",
    "    \"empty\": [0, 0, 0, 1],\n",
    "    \"walk\": [0, 0, 1, 0],\n",
    "    \"jump\": [0, 1, 0, 0],\n",
    "    \"wave\": [1, 0, 0, 0],\n",
    "}\n",
    "records_num = 150\n",
    "samples_num = records_num * len(classes)\n",
    "bandwidth = 40\n",
    "carriers_num = 108\n",
    "timestamps_num = 150\n",
    "x = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32f5dde",
   "metadata": {},
   "source": [
    "# Signal Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "491829e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_absolute_deviation(x):\n",
    "    \"\"\"\n",
    "    Returns the median absolute deviation from the window's median\n",
    "    :param x: Values in the window\n",
    "    :return: MAD\n",
    "    \"\"\"\n",
    "    return np.median(np.abs(x - np.median(x)))\n",
    "\n",
    "def hampel_d(ts, window_size=5, n=3, imputation=False):\n",
    "\n",
    "    \"\"\"\n",
    "    Median absolute deviation (MAD) outlier in Time Series\n",
    "    :param ts: a pandas Series object representing the timeseries\n",
    "    :param window_size: total window size will be computed as 2*window_size + 1\n",
    "    :param n: threshold, default is 3 (Pearson's rule)\n",
    "    :param imputation: If set to False, then the algorithm will be used for outlier detection.\n",
    "        If set to True, then the algorithm will also imput the outliers with the rolling median.\n",
    "    :return: Returns the outlier indices if imputation=False and the corrected timeseries if imputation=True\n",
    "    \"\"\"\n",
    "\n",
    "    if type(ts) != pd.Series:\n",
    "        raise ValueError(\"Timeserie object must be of tyme pandas.Series.\")\n",
    "\n",
    "    if type(window_size) != int:\n",
    "        raise ValueError(\"Window size must be of type integer.\")\n",
    "    else:\n",
    "        if window_size <= 0:\n",
    "            raise ValueError(\"Window size must be more than 0.\")\n",
    "\n",
    "    if type(n) != int:\n",
    "        raise ValueError(\"Window size must be of type integer.\")\n",
    "    else:\n",
    "        if n < 0:\n",
    "            raise ValueError(\"Window size must be equal or more than 0.\")\n",
    "\n",
    "    # Copy the Series object. This will be the cleaned timeserie\n",
    "    ts_cleaned = ts.copy()\n",
    "\n",
    "    # Constant scale factor, which depends on the distribution\n",
    "    # In this case, we assume normal distribution\n",
    "    k = 1.4826\n",
    "\n",
    "    rolling_ts = ts_cleaned.rolling(window_size*2, center=True)\n",
    "    rolling_median = rolling_ts.median().fillna(method='bfill').fillna(method='ffill')\n",
    "    rolling_sigma = k*(rolling_ts.apply(median_absolute_deviation).fillna(method='bfill').fillna(method='ffill'))\n",
    "\n",
    "    outlier_indices = list(\n",
    "        np.array(np.where(np.abs(ts_cleaned - rolling_median) >= (n * rolling_sigma))).flatten())\n",
    "\n",
    "    if imputation:\n",
    "        ts_cleaned[outlier_indices] = rolling_median[outlier_indices]\n",
    "        return ts_cleaned\n",
    "\n",
    "    return outlier_indices\n",
    "\n",
    "\n",
    "\n",
    "def hampel_filter_light(data, window_size=3, n_sigma=3):\n",
    "    n = len(data)\n",
    "    filtered = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        lower = max(0, i - window_size)\n",
    "        upper = min(n, i + window_size)\n",
    "        x = data[lower:upper]\n",
    "        median = np.median(x)\n",
    "        deviation = np.abs(x - median)\n",
    "        MAD = np.median(deviation)\n",
    "        threshold = n_sigma * MAD\n",
    "        if np.abs(data[i] - median) > threshold:\n",
    "            filtered[i] = median\n",
    "        else:\n",
    "            filtered[i] = data[i]\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dc8bc6",
   "metadata": {},
   "source": [
    "# Readers and processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cdb14a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pcap(label, idx):\n",
    "  samples_r = decoder(device).read_pcap(raw_data_path + '/' + label + '/R_' + label + '_00' + activity_code[label] + '_P150_' + str(idx).zfill(4) + '.pcap', bandwidth=bandwidth)\n",
    "\n",
    "  return decoder(device).unpack(samples_r['csi'], zero_nulls=False)\n",
    "\n",
    "def read_pcap_from(path):\n",
    "    samples_r = decoder(device).read_pcap(path, bandwidth=bandwidth)\n",
    "\n",
    "    return decoder(device).unpack(samples_r['csi'], zero_nulls=False)\n",
    "\n",
    "def read_csv(label, idx):\n",
    "  path = processed_path + '/' + label + '/' + label + '_' + str(idx + 1).zfill(4) + '.csv'\n",
    "  return np.genfromtxt(path, delimiter=',')\n",
    "\n",
    "def proccess_csi(csi):\n",
    "  csi = np.delete(csi, csi.dtype.metadata['nulls'] + csi.dtype.metadata['pilots'], axis=1)\n",
    "  csi = np.abs(csi)\n",
    "\n",
    "  for i in range(len(csi)):\n",
    "    csi[i] = list(hampel_d(pd.Series(csi[i]), 3, imputation=True))\n",
    "\n",
    "  csi = denoise_wavelet(csi, wavelet='sym6', mode='soft', wavelet_levels=3, method='BayesShrink', rescale_sigma='True')\n",
    "\n",
    "  return csi\n",
    "\n",
    "def proccess_csi_light(csi):\n",
    "  csi = np.delete(csi, csi.dtype.metadata['nulls'] + csi.dtype.metadata['pilots'], axis=1)\n",
    "  csi = np.abs(csi)\n",
    "\n",
    "  for i in range(len(csi)):\n",
    "    csi[i] = hampel_filter_light(csi[i])\n",
    "\n",
    "  csi = denoise_wavelet(csi, wavelet='sym6', mode='soft', wavelet_levels=3, method='BayesShrink', rescale_sigma='True')\n",
    "\n",
    "  return csi\n",
    "\n",
    "def read_and_process(path, separator = 9000):\n",
    "    csi = read_pcap_from(path)\n",
    "    csi = proccess_csi(csi)\n",
    "    csi = csi[:separator]\n",
    "\n",
    "    return np.array(np.split(csi.copy(), int(separator / timestamps_num)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf2d6c7",
   "metadata": {},
   "source": [
    "# Read dataset Data from CSV (preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81e41939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(label, idx):\n",
    "  path = processed_path + '/' + label + '/' + label + '_' + str(idx + 1).zfill(3) + '.csv'\n",
    "  return np.genfromtxt(path, delimiter=',')\n",
    "\n",
    "for label in classes:\n",
    "  for i in range(0, records_num):\n",
    "    y.append(label)\n",
    "    x.append(read_csv(label, i))\n",
    "\n",
    "for i in range(len(y)):\n",
    "  y[i] = activity_vector[y[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ccd185",
   "metadata": {},
   "source": [
    "# Or Read dataset Data from raw .pcap (and preprocess it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "bc7c7896",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'empty'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[143], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m   \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, records_num \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m      3\u001B[0m     y\u001B[38;5;241m.\u001B[39mappend(label)\n\u001B[1;32m----> 4\u001B[0m     x\u001B[38;5;241m.\u001B[39mappend(\u001B[43mread_pcap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(y)):\n\u001B[0;32m      7\u001B[0m   y[i] \u001B[38;5;241m=\u001B[39m activity_vector[y[i]]\n",
      "Cell \u001B[1;32mIn[141], line 2\u001B[0m, in \u001B[0;36mread_pcap\u001B[1;34m(label, idx)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mread_pcap\u001B[39m(label, idx):\n\u001B[1;32m----> 2\u001B[0m   samples_r \u001B[38;5;241m=\u001B[39m decoder(device)\u001B[38;5;241m.\u001B[39mread_pcap(raw_data_path \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m label \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/R_\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m label \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_00\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[43mactivity_code\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_P150_\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(idx)\u001B[38;5;241m.\u001B[39mzfill(\u001B[38;5;241m4\u001B[39m) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.pcap\u001B[39m\u001B[38;5;124m'\u001B[39m, bandwidth\u001B[38;5;241m=\u001B[39mbandwidth)\n\u001B[0;32m      4\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m decoder(device)\u001B[38;5;241m.\u001B[39munpack(samples_r[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcsi\u001B[39m\u001B[38;5;124m'\u001B[39m], zero_nulls\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'empty'"
     ]
    }
   ],
   "source": [
    "for label in classes:\n",
    "  for i in range(1, records_num + 1):\n",
    "    y.append(label)\n",
    "    x.append(read_pcap(label, i))\n",
    "\n",
    "for i in range(len(y)):\n",
    "  y[i] = activity_vector[y[i]]\n",
    "\n",
    "for i in range(len(x)):\n",
    "  x[i] = proccess_csi(x[i])\n",
    "\n",
    "for i in range(len(classes)):\n",
    "  for ri in range(0, records_num):\n",
    "    label = classes[i]\n",
    "    idx = records_num*i + ri\n",
    "    path = processed_path + '/' + label + '/' + label + '_' + str(ri + 1).zfill(4) + '.csv'\n",
    "    np.savetxt(path, np.asarray(x[idx]), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578a23a8",
   "metadata": {},
   "source": [
    "# Generate train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "343d39be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0]\n",
      " [0 1 0 0]\n",
      " [1 0 0 0]\n",
      " ...\n",
      " [0 0 1 0]\n",
      " [0 1 0 0]\n",
      " [0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "y1 = np.array(y.copy())\n",
    "x1 = np.array(x.copy())\n",
    "\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(x1, y1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=0.0001)\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "\n",
    "# Add an input layer with the specified input shape\n",
    "model.add(LSTM(units=125, input_shape=(150, 108), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Add a second LSTM layer\n",
    "model.add(LSTM(units=100))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Add four fully connected network layers with relu activation\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dense(units=16, activation='relu'))\n",
    "model.add(Dense(units=8, activation='relu'))\n",
    "\n",
    "# Add the classification layer with softmax activation\n",
    "model.add(Dense(units=4, activation='softmax'))\n",
    "\n",
    "# Compile the model with specified loss function and optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "15/15 [==============================] - 4s 175ms/step - loss: 1.3822 - accuracy: 0.2771 - val_loss: 1.3973 - val_accuracy: 0.1917\n",
      "Epoch 2/200\n",
      "15/15 [==============================] - 2s 142ms/step - loss: 1.3819 - accuracy: 0.2708 - val_loss: 1.3953 - val_accuracy: 0.2167\n",
      "Epoch 3/200\n",
      "15/15 [==============================] - 2s 141ms/step - loss: 1.3771 - accuracy: 0.2729 - val_loss: 1.3913 - val_accuracy: 0.2000\n",
      "Epoch 4/200\n",
      "15/15 [==============================] - 2s 142ms/step - loss: 1.3740 - accuracy: 0.2562 - val_loss: 1.3862 - val_accuracy: 0.2583\n",
      "Epoch 5/200\n",
      "15/15 [==============================] - 2s 140ms/step - loss: 1.3658 - accuracy: 0.2896 - val_loss: 1.3715 - val_accuracy: 0.2833\n",
      "Epoch 6/200\n",
      "15/15 [==============================] - 2s 141ms/step - loss: 1.3655 - accuracy: 0.3063 - val_loss: 1.3866 - val_accuracy: 0.2583\n",
      "Epoch 7/200\n",
      "15/15 [==============================] - 2s 141ms/step - loss: 1.3540 - accuracy: 0.3333 - val_loss: 1.3789 - val_accuracy: 0.2250\n",
      "Epoch 8/200\n",
      "15/15 [==============================] - 2s 141ms/step - loss: 1.3482 - accuracy: 0.3292 - val_loss: 1.3818 - val_accuracy: 0.2917\n",
      "Epoch 9/200\n",
      "15/15 [==============================] - 2s 141ms/step - loss: 1.3372 - accuracy: 0.3438 - val_loss: 1.3549 - val_accuracy: 0.2833\n",
      "Epoch 10/200\n",
      "15/15 [==============================] - 2s 142ms/step - loss: 1.3235 - accuracy: 0.3833 - val_loss: 1.3586 - val_accuracy: 0.3750\n",
      "Epoch 11/200\n",
      "15/15 [==============================] - 2s 143ms/step - loss: 1.3106 - accuracy: 0.4021 - val_loss: 1.3390 - val_accuracy: 0.3667\n",
      "Epoch 12/200\n",
      "15/15 [==============================] - 2s 143ms/step - loss: 1.2861 - accuracy: 0.4229 - val_loss: 1.3332 - val_accuracy: 0.4000\n",
      "Epoch 13/200\n",
      "15/15 [==============================] - 2s 143ms/step - loss: 1.2703 - accuracy: 0.4354 - val_loss: 1.2925 - val_accuracy: 0.3250\n",
      "Epoch 14/200\n",
      "15/15 [==============================] - 2s 141ms/step - loss: 1.2478 - accuracy: 0.4458 - val_loss: 1.2753 - val_accuracy: 0.3250\n",
      "Epoch 15/200\n",
      "15/15 [==============================] - 2s 142ms/step - loss: 1.2189 - accuracy: 0.4708 - val_loss: 1.2653 - val_accuracy: 0.3167\n",
      "Epoch 16/200\n",
      "15/15 [==============================] - 2s 143ms/step - loss: 1.2256 - accuracy: 0.4563 - val_loss: 1.2436 - val_accuracy: 0.3333\n",
      "Epoch 17/200\n",
      "15/15 [==============================] - 2s 141ms/step - loss: 1.2088 - accuracy: 0.4354 - val_loss: 1.2340 - val_accuracy: 0.3667\n",
      "Epoch 18/200\n",
      "15/15 [==============================] - 2s 142ms/step - loss: 1.1689 - accuracy: 0.4688 - val_loss: 1.2258 - val_accuracy: 0.3250\n",
      "Epoch 19/200\n",
      "15/15 [==============================] - 2s 142ms/step - loss: 1.1393 - accuracy: 0.4750 - val_loss: 1.2005 - val_accuracy: 0.3417\n",
      "Epoch 20/200\n",
      "15/15 [==============================] - 2s 150ms/step - loss: 1.1558 - accuracy: 0.4458 - val_loss: 1.2710 - val_accuracy: 0.3500\n",
      "Epoch 21/200\n",
      "15/15 [==============================] - 2s 151ms/step - loss: 1.1249 - accuracy: 0.4542 - val_loss: 1.1977 - val_accuracy: 0.3583\n",
      "Epoch 22/200\n",
      "15/15 [==============================] - 2s 150ms/step - loss: 1.1170 - accuracy: 0.4688 - val_loss: 1.1952 - val_accuracy: 0.3500\n",
      "Epoch 23/200\n",
      "15/15 [==============================] - 2s 150ms/step - loss: 1.1294 - accuracy: 0.4604 - val_loss: 1.2286 - val_accuracy: 0.3500\n",
      "Epoch 24/200\n",
      "15/15 [==============================] - 2s 150ms/step - loss: 1.1060 - accuracy: 0.4583 - val_loss: 1.1981 - val_accuracy: 0.3333\n",
      "Epoch 25/200\n",
      "15/15 [==============================] - 2s 150ms/step - loss: 1.0911 - accuracy: 0.4708 - val_loss: 1.1438 - val_accuracy: 0.3667\n",
      "Epoch 26/200\n",
      "15/15 [==============================] - 2s 151ms/step - loss: 1.1386 - accuracy: 0.4354 - val_loss: 1.1728 - val_accuracy: 0.3583\n",
      "Epoch 27/200\n",
      "15/15 [==============================] - 2s 151ms/step - loss: 1.1070 - accuracy: 0.4625 - val_loss: 1.1575 - val_accuracy: 0.3667\n",
      "Epoch 28/200\n",
      "15/15 [==============================] - 2s 150ms/step - loss: 1.0896 - accuracy: 0.4604 - val_loss: 1.1543 - val_accuracy: 0.3667\n",
      "Epoch 29/200\n",
      "15/15 [==============================] - 2s 151ms/step - loss: 1.0725 - accuracy: 0.4729 - val_loss: 1.1555 - val_accuracy: 0.3667\n",
      "Epoch 30/200\n",
      "15/15 [==============================] - 2s 151ms/step - loss: 1.0658 - accuracy: 0.4771 - val_loss: 1.1728 - val_accuracy: 0.3667\n",
      "Epoch 31/200\n",
      "15/15 [==============================] - 2s 150ms/step - loss: 1.0693 - accuracy: 0.4750 - val_loss: 1.2068 - val_accuracy: 0.3500\n",
      "Epoch 32/200\n",
      "15/15 [==============================] - 2s 150ms/step - loss: 1.0832 - accuracy: 0.4917 - val_loss: 1.3106 - val_accuracy: 0.3583\n",
      "Epoch 33/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 1.0437 - accuracy: 0.5125 - val_loss: 1.1725 - val_accuracy: 0.3667\n",
      "Epoch 34/200\n",
      "15/15 [==============================] - 2s 151ms/step - loss: 1.0311 - accuracy: 0.5063 - val_loss: 1.4923 - val_accuracy: 0.3250\n",
      "Epoch 35/200\n",
      "15/15 [==============================] - 2s 150ms/step - loss: 1.1160 - accuracy: 0.4521 - val_loss: 1.1761 - val_accuracy: 0.3583\n",
      "Epoch 36/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 1.0166 - accuracy: 0.5333 - val_loss: 1.0986 - val_accuracy: 0.4167\n",
      "Epoch 37/200\n",
      "15/15 [==============================] - 2s 150ms/step - loss: 0.9641 - accuracy: 0.5708 - val_loss: 1.1109 - val_accuracy: 0.4000\n",
      "Epoch 38/200\n",
      "15/15 [==============================] - 2s 150ms/step - loss: 0.9636 - accuracy: 0.5625 - val_loss: 1.1440 - val_accuracy: 0.4333\n",
      "Epoch 39/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.9343 - accuracy: 0.6000 - val_loss: 1.1071 - val_accuracy: 0.4833\n",
      "Epoch 40/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.9199 - accuracy: 0.6021 - val_loss: 1.1283 - val_accuracy: 0.4250\n",
      "Epoch 41/200\n",
      "15/15 [==============================] - 2s 150ms/step - loss: 0.9841 - accuracy: 0.5792 - val_loss: 1.3310 - val_accuracy: 0.3250\n",
      "Epoch 42/200\n",
      "15/15 [==============================] - 2s 151ms/step - loss: 1.0943 - accuracy: 0.4896 - val_loss: 1.1312 - val_accuracy: 0.4667\n",
      "Epoch 43/200\n",
      "15/15 [==============================] - 2s 151ms/step - loss: 0.9991 - accuracy: 0.5604 - val_loss: 1.1857 - val_accuracy: 0.4583\n",
      "Epoch 44/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.9506 - accuracy: 0.5792 - val_loss: 1.0894 - val_accuracy: 0.4917\n",
      "Epoch 45/200\n",
      "15/15 [==============================] - 2s 150ms/step - loss: 0.9302 - accuracy: 0.5979 - val_loss: 1.0911 - val_accuracy: 0.5083\n",
      "Epoch 46/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.9341 - accuracy: 0.6000 - val_loss: 1.1554 - val_accuracy: 0.4583\n",
      "Epoch 47/200\n",
      "15/15 [==============================] - 2s 151ms/step - loss: 1.0245 - accuracy: 0.5250 - val_loss: 1.1114 - val_accuracy: 0.5417\n",
      "Epoch 48/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.9416 - accuracy: 0.5917 - val_loss: 1.1698 - val_accuracy: 0.3833\n",
      "Epoch 49/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.9298 - accuracy: 0.5667 - val_loss: 1.1043 - val_accuracy: 0.4167\n",
      "Epoch 50/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.8902 - accuracy: 0.6083 - val_loss: 1.1032 - val_accuracy: 0.4833\n",
      "Epoch 51/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.8847 - accuracy: 0.6042 - val_loss: 1.5768 - val_accuracy: 0.4750\n",
      "Epoch 52/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 1.4869 - accuracy: 0.5021 - val_loss: 1.2690 - val_accuracy: 0.3917\n",
      "Epoch 53/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 1.0766 - accuracy: 0.4896 - val_loss: 1.1755 - val_accuracy: 0.4083\n",
      "Epoch 54/200\n",
      "15/15 [==============================] - 2s 150ms/step - loss: 0.9764 - accuracy: 0.5667 - val_loss: 1.1014 - val_accuracy: 0.4833\n",
      "Epoch 55/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.9194 - accuracy: 0.5708 - val_loss: 1.1599 - val_accuracy: 0.4417\n",
      "Epoch 56/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 1.0071 - accuracy: 0.5396 - val_loss: 1.1632 - val_accuracy: 0.4250\n",
      "Epoch 57/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 1.0251 - accuracy: 0.5292 - val_loss: 1.0829 - val_accuracy: 0.4833\n",
      "Epoch 58/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.9136 - accuracy: 0.5958 - val_loss: 1.6597 - val_accuracy: 0.4000\n",
      "Epoch 59/200\n",
      "15/15 [==============================] - 2s 151ms/step - loss: 1.3247 - accuracy: 0.4979 - val_loss: 1.3399 - val_accuracy: 0.3500\n",
      "Epoch 60/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.9697 - accuracy: 0.5500 - val_loss: 1.1127 - val_accuracy: 0.5167\n",
      "Epoch 61/200\n",
      "15/15 [==============================] - 2s 151ms/step - loss: 0.9307 - accuracy: 0.6083 - val_loss: 1.1572 - val_accuracy: 0.4500\n",
      "Epoch 62/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.8996 - accuracy: 0.6062 - val_loss: 1.0841 - val_accuracy: 0.4750\n",
      "Epoch 63/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.9128 - accuracy: 0.5938 - val_loss: 1.3518 - val_accuracy: 0.3333\n",
      "Epoch 64/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.9612 - accuracy: 0.5729 - val_loss: 1.1166 - val_accuracy: 0.4833\n",
      "Epoch 65/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.9063 - accuracy: 0.5979 - val_loss: 1.1328 - val_accuracy: 0.4667\n",
      "Epoch 66/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.8558 - accuracy: 0.6271 - val_loss: 1.0257 - val_accuracy: 0.5250\n",
      "Epoch 67/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.8354 - accuracy: 0.6229 - val_loss: 1.1302 - val_accuracy: 0.4750\n",
      "Epoch 68/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.8177 - accuracy: 0.6208 - val_loss: 1.0570 - val_accuracy: 0.5083\n",
      "Epoch 69/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.7886 - accuracy: 0.6292 - val_loss: 0.9919 - val_accuracy: 0.5417\n",
      "Epoch 70/200\n",
      "15/15 [==============================] - 2s 151ms/step - loss: 0.7850 - accuracy: 0.6354 - val_loss: 0.9279 - val_accuracy: 0.5417\n",
      "Epoch 71/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.7713 - accuracy: 0.6604 - val_loss: 0.9865 - val_accuracy: 0.5167\n",
      "Epoch 72/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.7640 - accuracy: 0.6562 - val_loss: 0.9135 - val_accuracy: 0.5417\n",
      "Epoch 73/200\n",
      "15/15 [==============================] - 2s 154ms/step - loss: 0.7881 - accuracy: 0.6271 - val_loss: 1.0997 - val_accuracy: 0.4667\n",
      "Epoch 74/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.7770 - accuracy: 0.6271 - val_loss: 0.8697 - val_accuracy: 0.5417\n",
      "Epoch 75/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.7415 - accuracy: 0.6438 - val_loss: 0.8898 - val_accuracy: 0.5500\n",
      "Epoch 76/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.7456 - accuracy: 0.6667 - val_loss: 0.7965 - val_accuracy: 0.6167\n",
      "Epoch 77/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.7389 - accuracy: 0.6458 - val_loss: 0.9037 - val_accuracy: 0.5500\n",
      "Epoch 78/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.7177 - accuracy: 0.6479 - val_loss: 0.9775 - val_accuracy: 0.5500\n",
      "Epoch 79/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.7246 - accuracy: 0.6583 - val_loss: 0.9152 - val_accuracy: 0.5500\n",
      "Epoch 80/200\n",
      "15/15 [==============================] - 2s 151ms/step - loss: 0.7337 - accuracy: 0.6667 - val_loss: 1.0545 - val_accuracy: 0.5083\n",
      "Epoch 81/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.8187 - accuracy: 0.6083 - val_loss: 0.9964 - val_accuracy: 0.5583\n",
      "Epoch 82/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.8051 - accuracy: 0.6417 - val_loss: 0.9878 - val_accuracy: 0.5250\n",
      "Epoch 83/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.8084 - accuracy: 0.6333 - val_loss: 1.2045 - val_accuracy: 0.4417\n",
      "Epoch 84/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.8402 - accuracy: 0.6167 - val_loss: 0.9402 - val_accuracy: 0.5333\n",
      "Epoch 85/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.8347 - accuracy: 0.6042 - val_loss: 0.9798 - val_accuracy: 0.5417\n",
      "Epoch 86/200\n",
      "15/15 [==============================] - 2s 154ms/step - loss: 0.7845 - accuracy: 0.6250 - val_loss: 0.8847 - val_accuracy: 0.5667\n",
      "Epoch 87/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.7524 - accuracy: 0.6479 - val_loss: 0.8492 - val_accuracy: 0.6083\n",
      "Epoch 88/200\n",
      "15/15 [==============================] - 2s 151ms/step - loss: 0.7441 - accuracy: 0.6458 - val_loss: 0.8804 - val_accuracy: 0.5583\n",
      "Epoch 89/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.7139 - accuracy: 0.6687 - val_loss: 0.9189 - val_accuracy: 0.5583\n",
      "Epoch 90/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.7415 - accuracy: 0.6292 - val_loss: 0.9146 - val_accuracy: 0.5667\n",
      "Epoch 91/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.8816 - accuracy: 0.5854 - val_loss: 0.9146 - val_accuracy: 0.5667\n",
      "Epoch 92/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.7755 - accuracy: 0.6417 - val_loss: 0.9004 - val_accuracy: 0.5833\n",
      "Epoch 93/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.7050 - accuracy: 0.6562 - val_loss: 0.8784 - val_accuracy: 0.5500\n",
      "Epoch 94/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.7129 - accuracy: 0.6750 - val_loss: 0.9056 - val_accuracy: 0.6083\n",
      "Epoch 95/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.7163 - accuracy: 0.6521 - val_loss: 0.8835 - val_accuracy: 0.5833\n",
      "Epoch 96/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.6834 - accuracy: 0.6792 - val_loss: 0.8677 - val_accuracy: 0.5417\n",
      "Epoch 97/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.6875 - accuracy: 0.6542 - val_loss: 0.9573 - val_accuracy: 0.5250\n",
      "Epoch 98/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.6745 - accuracy: 0.6667 - val_loss: 0.8617 - val_accuracy: 0.5750\n",
      "Epoch 99/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.7093 - accuracy: 0.6604 - val_loss: 1.3380 - val_accuracy: 0.4000\n",
      "Epoch 100/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.8073 - accuracy: 0.6146 - val_loss: 1.0286 - val_accuracy: 0.4917\n",
      "Epoch 101/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.8202 - accuracy: 0.6125 - val_loss: 0.9676 - val_accuracy: 0.4917\n",
      "Epoch 102/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.7590 - accuracy: 0.6458 - val_loss: 0.9085 - val_accuracy: 0.5000\n",
      "Epoch 103/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.7312 - accuracy: 0.6396 - val_loss: 0.8923 - val_accuracy: 0.5333\n",
      "Epoch 104/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.7000 - accuracy: 0.6583 - val_loss: 0.7716 - val_accuracy: 0.6250\n",
      "Epoch 105/200\n",
      "15/15 [==============================] - 2s 151ms/step - loss: 0.6992 - accuracy: 0.6646 - val_loss: 0.8857 - val_accuracy: 0.5250\n",
      "Epoch 106/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.6811 - accuracy: 0.6771 - val_loss: 0.8274 - val_accuracy: 0.5750\n",
      "Epoch 107/200\n",
      "15/15 [==============================] - 2s 154ms/step - loss: 0.6958 - accuracy: 0.6542 - val_loss: 0.7092 - val_accuracy: 0.6250\n",
      "Epoch 108/200\n",
      "15/15 [==============================] - 2s 155ms/step - loss: 0.6736 - accuracy: 0.6833 - val_loss: 0.8285 - val_accuracy: 0.5667\n",
      "Epoch 109/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.6653 - accuracy: 0.6792 - val_loss: 0.8957 - val_accuracy: 0.5333\n",
      "Epoch 110/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.6520 - accuracy: 0.6667 - val_loss: 0.8399 - val_accuracy: 0.5417\n",
      "Epoch 111/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.6534 - accuracy: 0.6792 - val_loss: 0.8625 - val_accuracy: 0.5417\n",
      "Epoch 112/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.7022 - accuracy: 0.6542 - val_loss: 0.7476 - val_accuracy: 0.5833\n",
      "Epoch 113/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.7041 - accuracy: 0.6583 - val_loss: 0.7299 - val_accuracy: 0.6083\n",
      "Epoch 114/200\n",
      "15/15 [==============================] - 2s 151ms/step - loss: 0.6956 - accuracy: 0.6562 - val_loss: 0.8709 - val_accuracy: 0.5333\n",
      "Epoch 115/200\n",
      "15/15 [==============================] - 2s 154ms/step - loss: 0.7200 - accuracy: 0.6458 - val_loss: 0.8151 - val_accuracy: 0.5917\n",
      "Epoch 116/200\n",
      "15/15 [==============================] - 2s 156ms/step - loss: 0.6551 - accuracy: 0.6708 - val_loss: 0.6934 - val_accuracy: 0.6167\n",
      "Epoch 117/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.6437 - accuracy: 0.6750 - val_loss: 0.7099 - val_accuracy: 0.6167\n",
      "Epoch 118/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.6203 - accuracy: 0.6938 - val_loss: 0.7084 - val_accuracy: 0.6083\n",
      "Epoch 119/200\n",
      "15/15 [==============================] - 2s 154ms/step - loss: 0.6458 - accuracy: 0.6708 - val_loss: 0.7234 - val_accuracy: 0.6000\n",
      "Epoch 120/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.6174 - accuracy: 0.6729 - val_loss: 0.7767 - val_accuracy: 0.5917\n",
      "Epoch 121/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.6259 - accuracy: 0.6917 - val_loss: 0.7710 - val_accuracy: 0.5750\n",
      "Epoch 122/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.5952 - accuracy: 0.6917 - val_loss: 1.0899 - val_accuracy: 0.4917\n",
      "Epoch 123/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.6685 - accuracy: 0.6875 - val_loss: 0.7575 - val_accuracy: 0.5667\n",
      "Epoch 124/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.6339 - accuracy: 0.6729 - val_loss: 0.7009 - val_accuracy: 0.6250\n",
      "Epoch 125/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.6056 - accuracy: 0.7021 - val_loss: 0.7751 - val_accuracy: 0.5833\n",
      "Epoch 126/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.6149 - accuracy: 0.6750 - val_loss: 0.7622 - val_accuracy: 0.5750\n",
      "Epoch 127/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.6289 - accuracy: 0.6854 - val_loss: 0.7373 - val_accuracy: 0.6167\n",
      "Epoch 128/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.6075 - accuracy: 0.6917 - val_loss: 0.6660 - val_accuracy: 0.6333\n",
      "Epoch 129/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.6565 - accuracy: 0.6833 - val_loss: 0.6913 - val_accuracy: 0.6417\n",
      "Epoch 130/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.5995 - accuracy: 0.6958 - val_loss: 0.7442 - val_accuracy: 0.6167\n",
      "Epoch 131/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.5806 - accuracy: 0.7188 - val_loss: 0.7715 - val_accuracy: 0.6333\n",
      "Epoch 132/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.6006 - accuracy: 0.7063 - val_loss: 0.7342 - val_accuracy: 0.5833\n",
      "Epoch 133/200\n",
      "15/15 [==============================] - 2s 151ms/step - loss: 0.6221 - accuracy: 0.6938 - val_loss: 0.7362 - val_accuracy: 0.6000\n",
      "Epoch 134/200\n",
      "15/15 [==============================] - 2s 155ms/step - loss: 0.6486 - accuracy: 0.6812 - val_loss: 0.9017 - val_accuracy: 0.5667\n",
      "Epoch 135/200\n",
      "15/15 [==============================] - 2s 154ms/step - loss: 0.6121 - accuracy: 0.6812 - val_loss: 0.8266 - val_accuracy: 0.6250\n",
      "Epoch 136/200\n",
      "15/15 [==============================] - 2s 154ms/step - loss: 0.6281 - accuracy: 0.6604 - val_loss: 0.7589 - val_accuracy: 0.5917\n",
      "Epoch 137/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.7354 - accuracy: 0.6438 - val_loss: 0.7613 - val_accuracy: 0.6583\n",
      "Epoch 138/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.6648 - accuracy: 0.6646 - val_loss: 0.8481 - val_accuracy: 0.6083\n",
      "Epoch 139/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.6326 - accuracy: 0.6771 - val_loss: 0.6466 - val_accuracy: 0.6833\n",
      "Epoch 140/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.6205 - accuracy: 0.6875 - val_loss: 0.8200 - val_accuracy: 0.5417\n",
      "Epoch 141/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.6418 - accuracy: 0.6583 - val_loss: 0.8096 - val_accuracy: 0.6083\n",
      "Epoch 142/200\n",
      "15/15 [==============================] - 2s 151ms/step - loss: 0.6426 - accuracy: 0.6771 - val_loss: 0.7033 - val_accuracy: 0.6583\n",
      "Epoch 143/200\n",
      "15/15 [==============================] - 2s 154ms/step - loss: 0.6083 - accuracy: 0.6958 - val_loss: 0.7988 - val_accuracy: 0.6000\n",
      "Epoch 144/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.6115 - accuracy: 0.6625 - val_loss: 0.8241 - val_accuracy: 0.5833\n",
      "Epoch 145/200\n",
      "15/15 [==============================] - 2s 154ms/step - loss: 0.5875 - accuracy: 0.6771 - val_loss: 0.8803 - val_accuracy: 0.5333\n",
      "Epoch 146/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.6473 - accuracy: 0.6771 - val_loss: 0.7318 - val_accuracy: 0.5833\n",
      "Epoch 147/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.6523 - accuracy: 0.6667 - val_loss: 0.6332 - val_accuracy: 0.6750\n",
      "Epoch 148/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.6028 - accuracy: 0.6938 - val_loss: 0.7347 - val_accuracy: 0.6167\n",
      "Epoch 149/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.6041 - accuracy: 0.6792 - val_loss: 0.7014 - val_accuracy: 0.6583\n",
      "Epoch 150/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.6080 - accuracy: 0.6896 - val_loss: 0.7201 - val_accuracy: 0.6167\n",
      "Epoch 151/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.6223 - accuracy: 0.6646 - val_loss: 0.8604 - val_accuracy: 0.5917\n",
      "Epoch 152/200\n",
      "15/15 [==============================] - 2s 154ms/step - loss: 0.6284 - accuracy: 0.6812 - val_loss: 0.6779 - val_accuracy: 0.6333\n",
      "Epoch 153/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.5825 - accuracy: 0.6896 - val_loss: 0.7146 - val_accuracy: 0.6250\n",
      "Epoch 154/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.6397 - accuracy: 0.6750 - val_loss: 0.7762 - val_accuracy: 0.6167\n",
      "Epoch 155/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.6473 - accuracy: 0.6896 - val_loss: 0.6816 - val_accuracy: 0.6417\n",
      "Epoch 156/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.6454 - accuracy: 0.6667 - val_loss: 0.9154 - val_accuracy: 0.5667\n",
      "Epoch 157/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.7847 - accuracy: 0.6396 - val_loss: 0.9112 - val_accuracy: 0.5500\n",
      "Epoch 158/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.6677 - accuracy: 0.6771 - val_loss: 0.7124 - val_accuracy: 0.6167\n",
      "Epoch 159/200\n",
      "15/15 [==============================] - 2s 154ms/step - loss: 0.6157 - accuracy: 0.6854 - val_loss: 0.6888 - val_accuracy: 0.6417\n",
      "Epoch 160/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.6327 - accuracy: 0.6687 - val_loss: 0.7096 - val_accuracy: 0.6333\n",
      "Epoch 161/200\n",
      "15/15 [==============================] - 2s 154ms/step - loss: 0.5980 - accuracy: 0.6792 - val_loss: 0.7143 - val_accuracy: 0.6250\n",
      "Epoch 162/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.6508 - accuracy: 0.6562 - val_loss: 0.7127 - val_accuracy: 0.5917\n",
      "Epoch 163/200\n",
      "15/15 [==============================] - 2s 154ms/step - loss: 0.6414 - accuracy: 0.6500 - val_loss: 1.0719 - val_accuracy: 0.4917\n",
      "Epoch 164/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.7020 - accuracy: 0.6750 - val_loss: 0.7562 - val_accuracy: 0.6333\n",
      "Epoch 165/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.6277 - accuracy: 0.6771 - val_loss: 0.7355 - val_accuracy: 0.6250\n",
      "Epoch 166/200\n",
      "15/15 [==============================] - 2s 154ms/step - loss: 0.6517 - accuracy: 0.6812 - val_loss: 0.7993 - val_accuracy: 0.5750\n",
      "Epoch 167/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.6510 - accuracy: 0.6479 - val_loss: 0.7796 - val_accuracy: 0.5833\n",
      "Epoch 168/200\n",
      "15/15 [==============================] - 2s 156ms/step - loss: 0.6533 - accuracy: 0.6646 - val_loss: 0.8435 - val_accuracy: 0.5667\n",
      "Epoch 169/200\n",
      "15/15 [==============================] - 2s 151ms/step - loss: 0.6108 - accuracy: 0.6729 - val_loss: 0.6740 - val_accuracy: 0.6333\n",
      "Epoch 170/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.5790 - accuracy: 0.6771 - val_loss: 0.7338 - val_accuracy: 0.6083\n",
      "Epoch 171/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.6359 - accuracy: 0.6542 - val_loss: 1.0487 - val_accuracy: 0.4917\n",
      "Epoch 172/200\n",
      "15/15 [==============================] - 2s 154ms/step - loss: 0.6448 - accuracy: 0.6729 - val_loss: 0.6997 - val_accuracy: 0.6083\n",
      "Epoch 173/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.7118 - accuracy: 0.6771 - val_loss: 0.6928 - val_accuracy: 0.6417\n",
      "Epoch 174/200\n",
      "15/15 [==============================] - 2s 151ms/step - loss: 0.6063 - accuracy: 0.6583 - val_loss: 0.8347 - val_accuracy: 0.5667\n",
      "Epoch 175/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.5713 - accuracy: 0.7125 - val_loss: 0.7414 - val_accuracy: 0.6250\n",
      "Epoch 176/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.6423 - accuracy: 0.6750 - val_loss: 0.7772 - val_accuracy: 0.5333\n",
      "Epoch 177/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.5696 - accuracy: 0.7104 - val_loss: 0.7275 - val_accuracy: 0.5833\n",
      "Epoch 178/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.5927 - accuracy: 0.7021 - val_loss: 1.0556 - val_accuracy: 0.5417\n",
      "Epoch 179/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.5849 - accuracy: 0.6938 - val_loss: 0.8674 - val_accuracy: 0.5833\n",
      "Epoch 180/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.6090 - accuracy: 0.6646 - val_loss: 0.7474 - val_accuracy: 0.6583\n",
      "Epoch 181/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.6238 - accuracy: 0.6917 - val_loss: 0.7666 - val_accuracy: 0.6500\n",
      "Epoch 182/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.5748 - accuracy: 0.6917 - val_loss: 1.0449 - val_accuracy: 0.5000\n",
      "Epoch 183/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.6508 - accuracy: 0.6667 - val_loss: 0.7056 - val_accuracy: 0.6000\n",
      "Epoch 184/200\n",
      "15/15 [==============================] - 2s 154ms/step - loss: 0.6023 - accuracy: 0.6958 - val_loss: 0.7819 - val_accuracy: 0.5583\n",
      "Epoch 185/200\n",
      "15/15 [==============================] - 2s 154ms/step - loss: 0.5887 - accuracy: 0.6792 - val_loss: 0.7425 - val_accuracy: 0.6500\n",
      "Epoch 186/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.5940 - accuracy: 0.6854 - val_loss: 0.7479 - val_accuracy: 0.6333\n",
      "Epoch 187/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.5687 - accuracy: 0.7229 - val_loss: 0.8566 - val_accuracy: 0.5750\n",
      "Epoch 188/200\n",
      "15/15 [==============================] - 2s 154ms/step - loss: 0.5815 - accuracy: 0.7063 - val_loss: 1.0120 - val_accuracy: 0.5083\n",
      "Epoch 189/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.5613 - accuracy: 0.7146 - val_loss: 0.6472 - val_accuracy: 0.6333\n",
      "Epoch 190/200\n",
      "15/15 [==============================] - 2s 154ms/step - loss: 0.5699 - accuracy: 0.6917 - val_loss: 0.6923 - val_accuracy: 0.6167\n",
      "Epoch 191/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.5558 - accuracy: 0.6833 - val_loss: 0.6654 - val_accuracy: 0.6333\n",
      "Epoch 192/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.6099 - accuracy: 0.6917 - val_loss: 0.6344 - val_accuracy: 0.6250\n",
      "Epoch 193/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.5652 - accuracy: 0.7396 - val_loss: 0.7260 - val_accuracy: 0.6000\n",
      "Epoch 194/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.5385 - accuracy: 0.7083 - val_loss: 0.7248 - val_accuracy: 0.6000\n",
      "Epoch 195/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.5461 - accuracy: 0.7083 - val_loss: 0.7223 - val_accuracy: 0.6000\n",
      "Epoch 196/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.5641 - accuracy: 0.7021 - val_loss: 0.7623 - val_accuracy: 0.6667\n",
      "Epoch 197/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.6341 - accuracy: 0.6771 - val_loss: 0.7959 - val_accuracy: 0.6000\n",
      "Epoch 198/200\n",
      "15/15 [==============================] - 2s 152ms/step - loss: 0.5864 - accuracy: 0.6833 - val_loss: 0.9762 - val_accuracy: 0.5667\n",
      "Epoch 199/200\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 0.5954 - accuracy: 0.6833 - val_loss: 0.6946 - val_accuracy: 0.6250\n",
      "Epoch 200/200\n",
      "15/15 [==============================] - 2s 156ms/step - loss: 0.6293 - accuracy: 0.6771 - val_loss: 0.7230 - val_accuracy: 0.6167\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.7230 - accuracy: 0.6167\n",
      "Test accuracy: 0.6166666746139526\n"
     ]
    }
   ],
   "source": [
    "# Train the model with the specified number of epochs and batch size\n",
    "model.fit(x_train, y_train, epochs=200, batch_size=32, validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "score = model.evaluate(x_test, y_test, batch_size=32)\n",
    "\n",
    "# Print the test accuracy\n",
    "print(\"Test accuracy:\", score[1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b23c76df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/lstm_o.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "646b5c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./models/lstm_o.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baf6371",
   "metadata": {},
   "source": [
    "# Processing and testing actual data from the room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65de9c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "packet_wave = read_and_process('./test/wave.pcap')\n",
    "packet_walk = read_and_process('./test/walk.pcap')\n",
    "packet_jump = read_and_process('./test/jump.pcap')\n",
    "packet_empty = read_and_process('./test/empty.pcap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da8591e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[1.00963689e-06, 1.04924981e-02, 2.54350714e-03, 9.86962974e-01],\n       [8.57307076e-01, 6.73609525e-02, 5.45369983e-02, 2.07949504e-02],\n       [9.56937075e-01, 2.09024195e-02, 1.91920437e-02, 2.96850665e-03],\n       [1.24893591e-01, 2.42506936e-01, 1.18422054e-01, 5.14177322e-01],\n       [9.10891175e-01, 3.98599580e-02, 4.15918492e-02, 7.65708974e-03],\n       [9.50963438e-01, 2.16226075e-02, 2.41292734e-02, 3.28475889e-03],\n       [9.28931713e-01, 3.10628787e-02, 3.41153145e-02, 5.89018641e-03],\n       [9.46153343e-01, 2.58114040e-02, 2.39649191e-02, 4.07030154e-03],\n       [9.62516665e-01, 1.93745736e-02, 1.54430410e-02, 2.66570877e-03],\n       [9.57832396e-01, 2.11029928e-02, 1.80965252e-02, 2.96799745e-03],\n       [9.51555967e-01, 2.56933719e-02, 1.91188920e-02, 3.63173499e-03],\n       [9.53241825e-01, 2.35375520e-02, 1.95219517e-02, 3.69869731e-03],\n       [9.18734353e-03, 5.08141339e-01, 4.76641715e-01, 6.02959888e-03],\n       [2.43016332e-01, 2.42836908e-01, 1.45997152e-01, 3.68149638e-01],\n       [1.22374886e-05, 2.16869880e-02, 6.47599623e-03, 9.71824825e-01],\n       [9.54391599e-01, 2.41031349e-02, 1.78598445e-02, 3.64533090e-03],\n       [3.39023450e-06, 1.49842687e-02, 3.84641276e-03, 9.81165946e-01],\n       [5.97700596e-01, 1.77675396e-01, 2.15581104e-01, 9.04295500e-03],\n       [9.80157331e-02, 4.01828110e-01, 4.91827399e-01, 8.32882617e-03],\n       [3.09491485e-01, 3.02236617e-01, 3.77976835e-01, 1.02950623e-02],\n       [9.08983827e-01, 4.45045307e-02, 3.62238586e-02, 1.02878101e-02],\n       [9.68250096e-01, 1.60980131e-02, 1.36240441e-02, 2.02787039e-03],\n       [9.37994003e-01, 3.43385935e-02, 2.25256961e-02, 5.14171924e-03],\n       [4.16113944e-05, 3.22983786e-02, 9.60388687e-03, 9.58056092e-01],\n       [9.59211409e-01, 1.96432900e-02, 1.81808304e-02, 2.96442490e-03],\n       [3.10935525e-06, 1.47491479e-02, 3.86923482e-03, 9.81378555e-01],\n       [9.11946654e-01, 3.91138233e-02, 4.39717174e-02, 4.96780640e-03],\n       [8.36059328e-08, 4.98373155e-03, 9.51145950e-04, 9.94065046e-01],\n       [5.58669686e-01, 2.04122230e-01, 9.95705575e-02, 1.37637571e-01],\n       [9.57472026e-01, 2.01091226e-02, 1.93880964e-02, 3.03069339e-03],\n       [4.01750475e-01, 2.60680676e-01, 3.28675032e-01, 8.89386795e-03],\n       [1.13537066e-01, 4.04933035e-01, 4.72267389e-01, 9.26254317e-03],\n       [9.57054853e-01, 1.92605034e-02, 2.07784642e-02, 2.90608243e-03],\n       [6.07102871e-01, 1.67985499e-01, 2.15738446e-01, 9.17318836e-03],\n       [8.99464488e-01, 4.44987565e-02, 5.13586551e-02, 4.67819022e-03],\n       [8.27258170e-01, 8.26437473e-02, 6.10899404e-02, 2.90081296e-02],\n       [1.55883583e-06, 1.14051932e-02, 3.20887333e-03, 9.85384285e-01],\n       [6.98521912e-01, 1.35725915e-01, 9.02891159e-02, 7.54630268e-02],\n       [4.79782075e-02, 2.34215826e-01, 1.02243930e-01, 6.15562022e-01],\n       [2.79823439e-06, 1.40842898e-02, 3.59418662e-03, 9.82318699e-01],\n       [2.94313375e-02, 4.49935645e-01, 5.14090776e-01, 6.54232549e-03],\n       [1.71562836e-01, 3.69657785e-01, 4.50003892e-01, 8.77545029e-03],\n       [9.67069924e-01, 1.67075973e-02, 1.40163079e-02, 2.20619887e-03],\n       [9.60107148e-01, 2.06739884e-02, 1.62422787e-02, 2.97660404e-03],\n       [8.63992284e-07, 9.85750090e-03, 2.34944280e-03, 9.87792194e-01],\n       [9.65389907e-01, 1.82437766e-02, 1.40254581e-02, 2.34085764e-03],\n       [9.61541116e-01, 1.96291823e-02, 1.60916056e-02, 2.73814378e-03],\n       [6.93576515e-01, 1.40982956e-01, 9.11696702e-02, 7.42708519e-02],\n       [6.81187885e-06, 1.85684543e-02, 5.25432080e-03, 9.76170421e-01],\n       [9.02578904e-07, 9.81154013e-03, 2.81668617e-03, 9.87370849e-01],\n       [9.50623751e-01, 2.49996446e-02, 2.03482583e-02, 4.02831426e-03],\n       [5.69711119e-07, 8.54490604e-03, 2.20414484e-03, 9.89250422e-01],\n       [8.74819279e-01, 5.47948554e-02, 6.47607744e-02, 5.62505657e-03],\n       [4.90487143e-02, 4.38709795e-01, 5.04293144e-01, 7.94838928e-03],\n       [9.62657809e-01, 1.79533400e-02, 1.68548077e-02, 2.53405189e-03],\n       [7.92962790e-01, 9.08611268e-02, 9.20079947e-02, 2.41680890e-02],\n       [2.03822921e-07, 6.65363111e-03, 1.32113043e-03, 9.92025137e-01],\n       [1.67751011e-07, 5.87634603e-03, 1.37252675e-03, 9.92751002e-01],\n       [8.77158701e-01, 5.88118732e-02, 4.70917635e-02, 1.69376116e-02],\n       [1.29298905e-06, 1.14461202e-02, 2.86515802e-03, 9.85687435e-01]],\n      dtype=float32)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(packet_empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fb639b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 37ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.32370362, 0.31142524, 0.26523185, 0.09963924],\n",
       "       [0.3175016 , 0.29446137, 0.25502643, 0.13301055],\n",
       "       [0.2638508 , 0.24664845, 0.37068588, 0.11881492],\n",
       "       [0.37742108, 0.1896247 , 0.30812183, 0.12483234],\n",
       "       [0.30501863, 0.27849606, 0.29363185, 0.12285345],\n",
       "       [0.82997394, 0.06373736, 0.07002258, 0.0362661 ],\n",
       "       [0.63440335, 0.18647622, 0.10468692, 0.0744335 ],\n",
       "       [0.33967894, 0.34293634, 0.12022132, 0.19716343],\n",
       "       [0.2816546 , 0.34880725, 0.2045532 , 0.16498497],\n",
       "       [0.27559614, 0.20833649, 0.4200614 , 0.09600585],\n",
       "       [0.7292721 , 0.12233413, 0.08331327, 0.06508051],\n",
       "       [0.2961744 , 0.18331821, 0.42727536, 0.09323207],\n",
       "       [0.6909223 , 0.14478666, 0.09460926, 0.06968174],\n",
       "       [0.5651567 , 0.22372092, 0.10842707, 0.10269531],\n",
       "       [0.6624264 , 0.17692184, 0.08915633, 0.07149537],\n",
       "       [0.49591926, 0.26753893, 0.1151256 , 0.12141616],\n",
       "       [0.3494325 , 0.17875418, 0.38622722, 0.08558612],\n",
       "       [0.7835809 , 0.08143532, 0.0828365 , 0.05214724],\n",
       "       [0.6999958 , 0.1565126 , 0.08621921, 0.05727234],\n",
       "       [0.3478199 , 0.21977463, 0.30488274, 0.12752275],\n",
       "       [0.35346055, 0.25075123, 0.24829394, 0.14749429],\n",
       "       [0.3366798 , 0.25807178, 0.2761128 , 0.12913562],\n",
       "       [0.47172365, 0.19359104, 0.24660294, 0.08808235],\n",
       "       [0.59458226, 0.19626953, 0.09421873, 0.11492953],\n",
       "       [0.32627878, 0.1756492 , 0.40876362, 0.08930843],\n",
       "       [0.48192555, 0.19773361, 0.22552371, 0.09481712],\n",
       "       [0.59037155, 0.21648842, 0.10982468, 0.08331532],\n",
       "       [0.55741507, 0.16259281, 0.18946432, 0.0905278 ],\n",
       "       [0.6886872 , 0.15844749, 0.08570568, 0.06715964],\n",
       "       [0.54998434, 0.23973495, 0.10890558, 0.10137513],\n",
       "       [0.45923635, 0.30462247, 0.10564433, 0.13049692],\n",
       "       [0.83771974, 0.06825521, 0.06424572, 0.02977935],\n",
       "       [0.6247182 , 0.1977885 , 0.1011544 , 0.07633891],\n",
       "       [0.43617117, 0.2430893 , 0.21533042, 0.10540907],\n",
       "       [0.6289205 , 0.15485896, 0.15712555, 0.05909494],\n",
       "       [0.6538483 , 0.14671122, 0.11719465, 0.08224588],\n",
       "       [0.6629229 , 0.1733998 , 0.0920835 , 0.07159383],\n",
       "       [0.5509508 , 0.2381836 , 0.10410998, 0.10675558],\n",
       "       [0.6524874 , 0.18060945, 0.08816963, 0.07873348],\n",
       "       [0.32875007, 0.19932531, 0.3829727 , 0.08895186],\n",
       "       [0.4616312 , 0.3094197 , 0.10616709, 0.12278203],\n",
       "       [0.83869547, 0.06652571, 0.06077024, 0.03400855],\n",
       "       [0.4971701 , 0.31700316, 0.09265104, 0.09317569],\n",
       "       [0.39949033, 0.39801362, 0.09010816, 0.11238787],\n",
       "       [0.2928428 , 0.25788137, 0.32610655, 0.12316922],\n",
       "       [0.5230216 , 0.2494251 , 0.13147958, 0.09607378],\n",
       "       [0.5697539 , 0.21935385, 0.10764074, 0.10325148],\n",
       "       [0.3794606 , 0.3605728 , 0.16178809, 0.09817852],\n",
       "       [0.31837574, 0.17190132, 0.40908232, 0.10064059],\n",
       "       [0.28215805, 0.32584473, 0.22660017, 0.16539703],\n",
       "       [0.3610276 , 0.26601568, 0.25141788, 0.12153878],\n",
       "       [0.4952548 , 0.2708718 , 0.10941429, 0.1244592 ],\n",
       "       [0.5885522 , 0.21093658, 0.10870987, 0.09180138],\n",
       "       [0.7635668 , 0.08327819, 0.08574633, 0.0674087 ],\n",
       "       [0.6101204 , 0.17457178, 0.1172001 , 0.09810769],\n",
       "       [0.7665425 , 0.10468866, 0.07816534, 0.05060349],\n",
       "       [0.5336002 , 0.25543022, 0.10397951, 0.10699009],\n",
       "       [0.6901119 , 0.13159786, 0.10055841, 0.0777318 ],\n",
       "       [0.34013537, 0.18756962, 0.3692813 , 0.10301372],\n",
       "       [0.3684285 , 0.29469672, 0.20790836, 0.1289664 ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(packet_wave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "325b8c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 37ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.44975525, 0.23948915, 0.19126551, 0.11949013],\n",
       "       [0.42482537, 0.2725803 , 0.21300717, 0.08958714],\n",
       "       [0.39971069, 0.25883192, 0.21305169, 0.1284057 ],\n",
       "       [0.41902572, 0.2558328 , 0.19152409, 0.13361734],\n",
       "       [0.40761298, 0.23814614, 0.22038525, 0.13385561],\n",
       "       [0.25139794, 0.32300496, 0.27716377, 0.14843333],\n",
       "       [0.5207796 , 0.20493653, 0.12892827, 0.14535561],\n",
       "       [0.3992982 , 0.25248057, 0.19862808, 0.1495931 ],\n",
       "       [0.37962127, 0.24019578, 0.2119013 , 0.1682816 ],\n",
       "       [0.41778916, 0.24318433, 0.22275896, 0.11626759],\n",
       "       [0.5458268 , 0.15807937, 0.23095626, 0.06513759],\n",
       "       [0.37899223, 0.295453  , 0.20871347, 0.11684135],\n",
       "       [0.23426935, 0.383652  , 0.22625546, 0.1558232 ],\n",
       "       [0.5264997 , 0.24781048, 0.09868243, 0.12700741],\n",
       "       [0.3242163 , 0.31006873, 0.18600644, 0.1797085 ],\n",
       "       [0.3975006 , 0.24839059, 0.20744969, 0.14665908],\n",
       "       [0.4125955 , 0.26413757, 0.21373567, 0.10953132],\n",
       "       [0.7022562 , 0.09706607, 0.13387232, 0.06680545],\n",
       "       [0.46054995, 0.1944804 , 0.25266558, 0.09230409],\n",
       "       [0.39242342, 0.22195297, 0.23899801, 0.14662555],\n",
       "       [0.6332531 , 0.1350723 , 0.11405276, 0.1176219 ],\n",
       "       [0.3414311 , 0.31548434, 0.1999331 , 0.14315145],\n",
       "       [0.44044343, 0.3044949 , 0.14188552, 0.11317619],\n",
       "       [0.50627273, 0.20375797, 0.13897511, 0.15099421],\n",
       "       [0.60418653, 0.19130279, 0.11695077, 0.08755992],\n",
       "       [0.44192472, 0.21118593, 0.21255727, 0.134332  ],\n",
       "       [0.79284936, 0.07921275, 0.07298735, 0.05495058],\n",
       "       [0.8412167 , 0.05638202, 0.06563462, 0.03676669],\n",
       "       [0.79600877, 0.07980997, 0.07053323, 0.05364806],\n",
       "       [0.85229033, 0.05530537, 0.05812398, 0.03428036],\n",
       "       [0.5138842 , 0.278409  , 0.09426828, 0.11343856],\n",
       "       [0.61089593, 0.20388699, 0.09952392, 0.08569317],\n",
       "       [0.65229625, 0.13101949, 0.11591491, 0.10076938],\n",
       "       [0.8625443 , 0.04473333, 0.07086253, 0.02185981],\n",
       "       [0.4360659 , 0.18632013, 0.25874147, 0.11887249],\n",
       "       [0.41108572, 0.26378626, 0.19489202, 0.13023597],\n",
       "       [0.36111596, 0.25554863, 0.26597583, 0.11735958],\n",
       "       [0.45289576, 0.27411637, 0.12895904, 0.14402886],\n",
       "       [0.522731  , 0.22745295, 0.13170892, 0.1181071 ],\n",
       "       [0.62446046, 0.12492988, 0.10894749, 0.14166224],\n",
       "       [0.46859026, 0.19766758, 0.20760147, 0.12614068],\n",
       "       [0.61457634, 0.18066815, 0.10986115, 0.0948944 ],\n",
       "       [0.35883132, 0.29376903, 0.23943353, 0.10796615],\n",
       "       [0.4850582 , 0.15321516, 0.2645353 , 0.09719139],\n",
       "       [0.40819797, 0.2331829 , 0.22812007, 0.13049905],\n",
       "       [0.48691496, 0.25563052, 0.12082813, 0.13662641],\n",
       "       [0.38128453, 0.19730578, 0.3063416 , 0.11506807],\n",
       "       [0.31021732, 0.32409796, 0.19781847, 0.16786623],\n",
       "       [0.45162693, 0.22683908, 0.21799332, 0.10354067],\n",
       "       [0.7892503 , 0.09913473, 0.06535882, 0.0462561 ],\n",
       "       [0.4221447 , 0.24842837, 0.2244624 , 0.10496455],\n",
       "       [0.51246834, 0.28854007, 0.10029866, 0.09869292],\n",
       "       [0.57261384, 0.21940346, 0.09014012, 0.11784254],\n",
       "       [0.45150563, 0.18073231, 0.26121908, 0.10654294],\n",
       "       [0.42035323, 0.22637694, 0.2262445 , 0.12702537],\n",
       "       [0.43212038, 0.24549977, 0.171454  , 0.15092589],\n",
       "       [0.49757424, 0.18168399, 0.23933975, 0.08140208],\n",
       "       [0.6389314 , 0.1807881 , 0.09611673, 0.08416384],\n",
       "       [0.30972672, 0.17421824, 0.430058  , 0.08599702],\n",
       "       [0.2626445 , 0.28512502, 0.3178615 , 0.13436899]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(packet_walk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e951db82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 43ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.8359353 , 0.04230146, 0.0842602 , 0.03750303],\n",
       "       [0.8542182 , 0.03524317, 0.08044513, 0.03009342],\n",
       "       [0.7963921 , 0.06007487, 0.08312363, 0.06040948],\n",
       "       [0.86207634, 0.03054426, 0.07924587, 0.0281335 ],\n",
       "       [0.84945863, 0.03585526, 0.07594498, 0.03874115],\n",
       "       [0.85211   , 0.03242475, 0.07781545, 0.03764979],\n",
       "       [0.81222045, 0.04438248, 0.09309618, 0.05030084],\n",
       "       [0.89113915, 0.02418866, 0.06074667, 0.02392556],\n",
       "       [0.8816172 , 0.03015577, 0.06682513, 0.0214019 ],\n",
       "       [0.7723219 , 0.07149473, 0.08528293, 0.07090045],\n",
       "       [0.812346  , 0.04784256, 0.08659967, 0.05321181],\n",
       "       [0.7622188 , 0.0716893 , 0.10476804, 0.06132391],\n",
       "       [0.85014105, 0.03965206, 0.07207339, 0.03813352],\n",
       "       [0.8913319 , 0.02552658, 0.0609456 , 0.02219588],\n",
       "       [0.7998556 , 0.06554238, 0.08569609, 0.04890587],\n",
       "       [0.8204845 , 0.0516321 , 0.08507801, 0.04280543],\n",
       "       [0.8011846 , 0.06156729, 0.08864123, 0.04860693],\n",
       "       [0.8761184 , 0.02470079, 0.07183226, 0.02734843],\n",
       "       [0.8348553 , 0.04207525, 0.08764948, 0.03541994],\n",
       "       [0.7699497 , 0.06417871, 0.09611708, 0.06975447],\n",
       "       [0.78972816, 0.05866382, 0.10207248, 0.04953546],\n",
       "       [0.8343708 , 0.04360512, 0.08076351, 0.04126051],\n",
       "       [0.8320622 , 0.04009799, 0.08639643, 0.04144346],\n",
       "       [0.85676926, 0.03779011, 0.07107994, 0.03436075],\n",
       "       [0.8393379 , 0.03950735, 0.08290436, 0.03825036],\n",
       "       [0.7722552 , 0.0690842 , 0.08803483, 0.07062574],\n",
       "       [0.8043615 , 0.05550567, 0.09770089, 0.04243201],\n",
       "       [0.8365732 , 0.03857796, 0.08911689, 0.03573203],\n",
       "       [0.8021156 , 0.0520184 , 0.09055323, 0.05531273],\n",
       "       [0.7228848 , 0.09701706, 0.11286347, 0.06723469],\n",
       "       [0.81331885, 0.04207783, 0.09220131, 0.05240197],\n",
       "       [0.8530505 , 0.03377999, 0.08138549, 0.03178408],\n",
       "       [0.80838853, 0.05242888, 0.08418465, 0.05499793],\n",
       "       [0.8527895 , 0.03563628, 0.07481866, 0.0367556 ],\n",
       "       [0.8331538 , 0.04243198, 0.08175676, 0.04265749],\n",
       "       [0.7972817 , 0.05165277, 0.0978635 , 0.05320206],\n",
       "       [0.83565974, 0.04851004, 0.07539473, 0.04043548],\n",
       "       [0.8763827 , 0.03431885, 0.05934573, 0.02995275],\n",
       "       [0.8128655 , 0.04950328, 0.09202348, 0.04560771],\n",
       "       [0.80949384, 0.05036461, 0.09233139, 0.04781008],\n",
       "       [0.8048596 , 0.05388705, 0.09494312, 0.04631028],\n",
       "       [0.81448925, 0.05170567, 0.08885245, 0.04495266],\n",
       "       [0.80087817, 0.05091514, 0.09341815, 0.0547885 ],\n",
       "       [0.87177855, 0.0324853 , 0.07007733, 0.02565881],\n",
       "       [0.84316975, 0.03732419, 0.08382025, 0.03568592],\n",
       "       [0.8653276 , 0.0354217 , 0.06667065, 0.03258001],\n",
       "       [0.7926055 , 0.05645116, 0.09641685, 0.05452642],\n",
       "       [0.80749977, 0.05748146, 0.08386341, 0.0511553 ],\n",
       "       [0.8959994 , 0.02648064, 0.05698401, 0.02053598],\n",
       "       [0.84596676, 0.04211497, 0.07871389, 0.03320446],\n",
       "       [0.8539734 , 0.03872583, 0.0759847 , 0.03131603],\n",
       "       [0.82739866, 0.04069445, 0.08582849, 0.04607842],\n",
       "       [0.81516063, 0.05801815, 0.07825486, 0.04856633],\n",
       "       [0.8305053 , 0.04358034, 0.08753742, 0.03837689],\n",
       "       [0.8757435 , 0.02634669, 0.07494264, 0.02296713],\n",
       "       [0.81178343, 0.05180559, 0.08302168, 0.05338923],\n",
       "       [0.85439533, 0.03617432, 0.07365673, 0.03577363],\n",
       "       [0.81697184, 0.04796692, 0.08913743, 0.0459238 ],\n",
       "       [0.75011486, 0.0869959 , 0.0899248 , 0.07296438],\n",
       "       [0.8816424 , 0.03233672, 0.06099568, 0.02502521]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(packet_jump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy import signal\n",
    "\n",
    "# Load the dataset\n",
    "data = np.array(x.copy())\n",
    "labels = np.array(y.copy())\n",
    "\n",
    "# Preprocess the data\n",
    "# Resample the data along the time axis\n",
    "def resample_row(row):\n",
    "    return signal.resample(row, 200)\n",
    "\n",
    "data = np.apply_along_axis(resample_row, axis=1, arr=data) # Resample the data to 200 samples\n",
    "data = np.abs(data)  # Take the absolute value of the data\n",
    "data = np.log(data + 1)  # Apply logarithmic scaling to the data\n",
    "\n",
    "# Encode the labels\n",
    "#label_encoder = LabelEncoder()\n",
    "#labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "85867917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\mok93\\PycharmProjects\\csi_nn\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\mok93\\PycharmProjects\\csi_nn\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\mok93\\PycharmProjects\\csi_nn\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\mok93\\PycharmProjects\\csi_nn\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\mok93\\PycharmProjects\\csi_nn\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\mok93\\PycharmProjects\\csi_nn\\venv\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_4\" is incompatible with the layer: expected shape=(None, 200, 108), found shape=(32, 150, 108)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[49], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Evaluate the model on the test set\u001B[39;00m\n\u001B[0;32m      5\u001B[0m loss, accuracy \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mevaluate(x_test, y_test)\n",
      "File \u001B[1;32m~\\PycharmProjects\\csi_nn\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileci08xrrz.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001B[1;34m(iterator)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(step_function), (ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m), ag__\u001B[38;5;241m.\u001B[39mld(iterator)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[0;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: in user code:\n\n    File \"C:\\Users\\mok93\\PycharmProjects\\csi_nn\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\mok93\\PycharmProjects\\csi_nn\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\mok93\\PycharmProjects\\csi_nn\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\mok93\\PycharmProjects\\csi_nn\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\mok93\\PycharmProjects\\csi_nn\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\mok93\\PycharmProjects\\csi_nn\\venv\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_4\" is incompatible with the layer: expected shape=(None, 200, 108), found shape=(32, 150, 108)\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=16, validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "560c7fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(5759, 200, 108)"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def proccess_label(label):\n",
    "    data = np.split(read_pcap_from('./train_data/'+ label + '.pcap'), 150)\n",
    "\n",
    "    for ri in range(np.shape(data)[0]):\n",
    "        csi = proccess_csi(data[ri])\n",
    "        path = './train_data/' + label + '/' + label + '_' + str(ri + 1).zfill(3) + '.csv'\n",
    "        np.savetxt(path, np.asarray(csi), delimiter=\",\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "proccess_label('empty')\n",
    "proccess_label('walk')\n",
    "proccess_label('jump')\n",
    "proccess_label('wave')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
